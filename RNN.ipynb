{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total parameters: 102585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200256, 40, 57) (200256, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3129it [31:01,  1.68it/s]\n",
      "INFO:root:Epoch:0, train loss: 2.988773020562052, train accuracy: 0.19096057046979864, elapsed: 3501.738876104355 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \", for example, are of this origin. in sp\"\n",
      ", for example, are of this origin. in sp t on cs thi in\n",
      "\n",
      "\n",
      "iten the se e\n",
      "\n",
      "\n",
      "e in\n",
      "e se thale\n",
      " b\n",
      "\n",
      "e see iseen the reeere tin tin anthn atiin the"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [01:15,  1.73it/s]"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from algora.datasets import load_nietzsche\n",
    "from algora.neuralnet import NeuralNet\n",
    "from algora.neuralnet.constraints import SmallNorm\n",
    "from algora.neuralnet.layers import Activation, Dense\n",
    "from algora.neuralnet.layers.recurrent import LSTM, RNN\n",
    "from algora.neuralnet.optimizers import RMSprop\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "# Example taken from: https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "X, y, text, chars, char_indices, indices_char = load_nietzsche()\n",
    "# Round the number of sequences for batch processing\n",
    "items_count = X.shape[0] - (X.shape[0] % 64)\n",
    "maxlen = X.shape[1]\n",
    "X = X[0:items_count]\n",
    "y = y[0:items_count]\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# LSTM OR RNN\n",
    "# rnn_layer = RNN(128, return_sequences=False)\n",
    "rnn_layer = LSTM(128, return_sequences=False, )\n",
    "\n",
    "model = NeuralNet(\n",
    "    layers=[\n",
    "        rnn_layer,\n",
    "        # Flatten(),\n",
    "        # TimeStepSlicer(-1),\n",
    "        Dense(X.shape[2]),\n",
    "        Activation('softmax'),\n",
    "    ],\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metric='accuracy',\n",
    "    batch_size=64,\n",
    "    max_epochs=1,\n",
    "    shuffle=False,\n",
    "\n",
    ")\n",
    "\n",
    "for _ in range(25):\n",
    "    model.fit(X, y)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(100):\n",
    "        x = np.zeros((64, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        preds = model.predict(x)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
