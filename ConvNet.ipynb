{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import autograd.numpy as np\n",
    "\n",
    "from algora.neuralnet.layers import Layer, ParamMixin\n",
    "from algora.neuralnet.parameters import Parameters\n",
    "\n",
    "\n",
    "class Convolution(Layer, ParamMixin):\n",
    "    def __init__(self, n_filters=8, filter_shape=(3, 3), padding=(0, 0), stride=(1, 1), parameters=None):\n",
    "        \"\"\"A 2D convolutional layer.\n",
    "        Input shape: (n_images, n_channels, height, width)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_filters : int, default 8\n",
    "            The number of filters (kernels).\n",
    "        filter_shape : tuple(int, int), default (3, 3)\n",
    "            The shape of the filters. (height, width)\n",
    "        parameters : Parameters instance, default None\n",
    "        stride : tuple(int, int), default (1, 1)\n",
    "            The step of the convolution. (height, width).\n",
    "        padding : tuple(int, int), default (0, 0)\n",
    "            The number of pixel to add to each side of the input. (height, weight)\n",
    "\n",
    "        \"\"\"\n",
    "        self.padding = padding\n",
    "        self._params = parameters\n",
    "        self.stride = stride\n",
    "        self.filter_shape = filter_shape\n",
    "        self.n_filters = n_filters\n",
    "        if self._params is None:\n",
    "            self._params = Parameters()\n",
    "\n",
    "    def setup(self, X_shape):\n",
    "        n_channels, self.height, self.width = X_shape[1:]\n",
    "\n",
    "        W_shape = (self.n_filters, n_channels) + self.filter_shape\n",
    "        b_shape = (self.n_filters)\n",
    "        self._params.setup_weights(W_shape, b_shape)\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        n_images, n_channels, height, width = self.shape(X.shape)\n",
    "        self.last_input = X\n",
    "        self.col = image_to_column(X, self.filter_shape, self.stride, self.padding)\n",
    "        self.col_W = self._params['W'].reshape(self.n_filters, -1).T\n",
    "\n",
    "        out = np.dot(self.col, self.col_W) + self._params['b']\n",
    "        out = out.reshape(n_images, height, width, -1).transpose(0, 3, 1, 2)\n",
    "        return out\n",
    "\n",
    "    def backward_pass(self, delta):\n",
    "        delta = delta.transpose(0, 2, 3, 1).reshape(-1, self.n_filters)\n",
    "\n",
    "        d_W = np.dot(self.col.T, delta).transpose(1, 0).reshape(self._params['W'].shape)\n",
    "        d_b = np.sum(delta, axis=0)\n",
    "        self._params.update_grad('b', d_b)\n",
    "        self._params.update_grad('W', d_W)\n",
    "\n",
    "        d_c = np.dot(delta, self.col_W.T)\n",
    "        return column_to_image(d_c, self.last_input.shape, self.filter_shape, self.stride, self.padding)\n",
    "\n",
    "    def shape(self, x_shape):\n",
    "        height, width = convoltuion_shape(self.height, self.width, self.filter_shape, self.stride, self.padding)\n",
    "        return x_shape[0], self.n_filters, height, width\n",
    "\n",
    "\n",
    "class MaxPooling(Layer):\n",
    "    def __init__(self, pool_shape=(2, 2), stride=(1, 1), padding=(0, 0)):\n",
    "        \"\"\"Max pooling layer.\n",
    "        Input shape: (n_images, n_channels, height, width)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pool_shape : tuple(int, int), default (2, 2)\n",
    "        stride : tuple(int, int), default (1,1)\n",
    "        padding : tuple(int, int), default (0,0)\n",
    "        \"\"\"\n",
    "        self.pool_shape = pool_shape\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        self.last_input = X\n",
    "\n",
    "        out_height, out_width = pooling_shape(self.pool_shape, X.shape, self.stride)\n",
    "        n_images, n_channels, _, _ = X.shape\n",
    "\n",
    "        col = image_to_column(X, self.pool_shape, self.stride, self.padding)\n",
    "        col = col.reshape(-1, self.pool_shape[0] * self.pool_shape[1])\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        self.arg_max = arg_max\n",
    "        return out.reshape(n_images, out_height, out_width, n_channels).transpose(0, 3, 1, 2)\n",
    "\n",
    "    def backward_pass(self, delta):\n",
    "        delta = delta.transpose(0, 2, 3, 1)\n",
    "\n",
    "        pool_size = self.pool_shape[0] * self.pool_shape[1]\n",
    "        y_max = np.zeros((delta.size, pool_size))\n",
    "        y_max[np.arange(self.arg_max.size), self.arg_max.flatten()] = delta.flatten()\n",
    "        y_max = y_max.reshape(delta.shape + (pool_size,))\n",
    "\n",
    "        dcol = y_max.reshape(y_max.shape[0] * y_max.shape[1] * y_max.shape[2], -1)\n",
    "        return column_to_image(dcol, self.last_input.shape, self.pool_shape, self.stride, self.padding)\n",
    "\n",
    "    def shape(self, x_shape):\n",
    "        h, w = convoltuion_shape(x_shape[2], x_shape[3], self.pool_shape, self.stride, self.padding)\n",
    "        return x_shape[0], x_shape[1], h, w\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    \"\"\"Flattens multidimensional input into 2D matrix.\"\"\"\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        self.last_input_shape = X.shape\n",
    "        return X.reshape((X.shape[0], -1))\n",
    "\n",
    "    def backward_pass(self, delta):\n",
    "        return delta.reshape(self.last_input_shape)\n",
    "\n",
    "    def shape(self, x_shape):\n",
    "        return x_shape[0], np.prod(x_shape[1:])\n",
    "\n",
    "\n",
    "def image_to_column(images, filter_shape, stride, padding):\n",
    "    \"\"\"Rearrange image blocks into columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    filter_shape : tuple(height, width)\n",
    "    images : np.array, shape (n_images, n_channels, height, width)\n",
    "    padding: tuple(height, width)\n",
    "    stride : tuple (height, width)\n",
    "\n",
    "    \"\"\"\n",
    "    n_images, n_channels, height, width = images.shape\n",
    "    f_height, f_width = filter_shape\n",
    "    out_height, out_width = convoltuion_shape(height, width, (f_height, f_width), stride, padding)\n",
    "    images = np.pad(images, ((0, 0), (0, 0), padding, padding), mode='constant')\n",
    "\n",
    "    col = np.zeros((n_images, n_channels, f_height, f_width, out_height, out_width))\n",
    "    for y in range(f_height):\n",
    "        y_bound = y + stride[0] * out_height\n",
    "        for x in range(f_width):\n",
    "            x_bound = x + stride[1] * out_width\n",
    "            col[:, :, y, x, :, :] = images[:, :, y:y_bound:stride[0], x:x_bound:stride[1]]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(n_images * out_height * out_width, -1)\n",
    "    return col\n",
    "\n",
    "\n",
    "def column_to_image(columns, images_shape, filter_shape, stride, padding):\n",
    "    \"\"\"Rearrange columns into image blocks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns\n",
    "    images_shape : tuple(n_images, n_channels, height, width)\n",
    "    filter_shape : tuple(height, _width)\n",
    "    stride : tuple(height, width)\n",
    "    padding : tuple(height, width)\n",
    "    \"\"\"\n",
    "    n_images, n_channels, height, width = images_shape\n",
    "    f_height, f_width = filter_shape\n",
    "\n",
    "    out_height, out_width = convoltuion_shape(height, width, (f_height, f_width), stride, padding)\n",
    "    columns = columns.reshape(n_images, out_height, out_width, n_channels, f_height, f_width).transpose(0, 3, 4, 5, 1,\n",
    "                                                                                                        2)\n",
    "\n",
    "    img_h = height + 2 * padding[0] + stride[0] - 1\n",
    "    img_w = width + 2 * padding[1] + stride[1] - 1\n",
    "    img = np.zeros((n_images, n_channels, img_h, img_w))\n",
    "    for y in range(f_height):\n",
    "        y_bound = y + stride[0] * out_height\n",
    "        for x in range(f_width):\n",
    "            x_bound = x + stride[1] * out_width\n",
    "            img[:, :, y:y_bound:stride[0], x:x_bound:stride[1]] += columns[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, padding[0]:height + padding[0], padding[1]:width + padding[1]]\n",
    "\n",
    "\n",
    "def convoltuion_shape(img_height, img_width, filter_shape, stride, padding):\n",
    "    \"\"\"Calculate output shape for convolution layer.\"\"\"\n",
    "    height = (img_height + 2 * padding[0] - filter_shape[0]) / float(stride[0]) + 1\n",
    "    width = (img_width + 2 * padding[1] - filter_shape[1]) / float(stride[1]) + 1\n",
    "\n",
    "    assert height % 1 == 0\n",
    "    assert width % 1 == 0\n",
    "\n",
    "    return int(height), int(width)\n",
    "\n",
    "\n",
    "def pooling_shape(pool_shape, image_shape, stride):\n",
    "    \"\"\"Calculate output shape for pooling layer.\"\"\"\n",
    "    n_images, n_channels, height, width = image_shape\n",
    "\n",
    "    height = (height - pool_shape[0]) / float(stride[0]) + 1\n",
    "    width = (width - pool_shape[1]) / float(stride[1]) + 1\n",
    "\n",
    "    assert height % 1 == 0\n",
    "    assert width % 1 == 0\n",
    "\n",
    "    return int(height), int(width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total parameters: 813802\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28) (60000, 10) (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [14:08,  1.81s/it]\n",
      "INFO:root:Epoch:0, train loss: 0.813392389987334, train accuracy: 0.9236666666666666, elapsed: 1180.5893449783325 sec.\n",
      "469it [13:10,  1.69s/it]\n",
      "INFO:root:Epoch:1, train loss: 0.31544072679676277, train accuracy: 0.95035, elapsed: 2723.724284887314 sec.\n",
      "469it [14:21,  1.84s/it]\n",
      "INFO:root:Epoch:2, train loss: 0.22362627237913768, train accuracy: 0.9662666666666667, elapsed: 1274.1737389564514 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9662\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from algora.datasets import load_mnist\n",
    "from algora.metrics import accuracy\n",
    "from algora.neuralnet import NeuralNet\n",
    "from algora.neuralnet.layers import Activation, Convolution, MaxPooling, Flatten, Dropout, Parameters\n",
    "from algora.neuralnet.layers import Dense\n",
    "from algora.neuralnet.optimizers import Adadelta\n",
    "from algora.utils import one_hot\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "X_train, X_test, y_train, y_test = load_mnist()\n",
    "\n",
    "# Normalize data\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "y_train = one_hot(y_train.flatten())\n",
    "y_test = one_hot(y_test.flatten())\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Approx. 15-20 min. per epoch\n",
    "# Took 2 hours on a Mac Air\n",
    "model = NeuralNet(\n",
    "    layers=[\n",
    "        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n",
    "        Activation('relu'),\n",
    "        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling(pool_shape=(2, 2), stride=(2, 2)),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10),\n",
    "        Activation('softmax'),\n",
    "    ],\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adadelta(),\n",
    "    metric='accuracy',\n",
    "    batch_size=128,\n",
    "    max_epochs=3,\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(accuracy(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
