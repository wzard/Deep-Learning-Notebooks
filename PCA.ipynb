{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from algora.base import BaseEstimator\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "class PCA(BaseEstimator):\n",
    "    y_required = False\n",
    "\n",
    "    def __init__(self, n_components, solver='svd'):\n",
    "        \"\"\"Principal component analysis (PCA) implementation.\n",
    "\n",
    "        Transforms a dataset of possibly correlated values into n linearly\n",
    "        uncorrelated components. The components are ordered such that the first\n",
    "        has the largest possible variance and each following component as the\n",
    "        largest possible variance given the previous components. This causes\n",
    "        the early components to contain most of the variability in the dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_components : int\n",
    "        solver : str, default 'svd'\n",
    "            {'svd', 'eigen'}\n",
    "        \"\"\"\n",
    "        self.solver = solver\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self._decompose(X)\n",
    "\n",
    "    def _decompose(self, X):\n",
    "        # Mean centering\n",
    "        X = X.copy()\n",
    "        X -= self.mean\n",
    "\n",
    "        if self.solver == 'svd':\n",
    "            _, s, Vh = svd(X, full_matrices=True)\n",
    "        elif self.solver == 'eigen':\n",
    "            s, Vh = np.linalg.eig(np.cov(X.T))\n",
    "            Vh = Vh.T\n",
    "\n",
    "        s_squared = s ** 2\n",
    "        variance_ratio = s_squared / (s_squared).sum()\n",
    "        logging.info('Explained variance ratio: %s' % (variance_ratio[0:self.n_components]))\n",
    "        self.components = Vh[0:self.n_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X -= self.mean\n",
    "        return np.dot(X, self.components.T)\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharth/miniconda3/lib/python3.6/site-packages/autograd/tracer.py:48: RuntimeWarning: overflow encountered in cosh\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Users/siddharth/miniconda3/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:88: RuntimeWarning: overflow encountered in square\n",
      "  defvjp(anp.tanh,   lambda ans, x : lambda g: g / anp.cosh(x) **2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for svd PCA: 0.92\n",
      "Classification accuracy for eigen PCA: 0.912\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from algora.linear_models import LogisticRegression\n",
    "from algora.metrics import accuracy\n",
    "from algora.pca import PCA\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Generate a random binary classification problem.\n",
    "X, y = make_classification(n_samples=1000, n_features=100, n_informative=75,\n",
    "                           random_state=1111, n_classes=2, class_sep=2.5, )\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                        random_state=1111)\n",
    "\n",
    "for s in ['svd', 'eigen']:\n",
    "    p = PCA(15, solver=s)\n",
    "\n",
    "    # fit PCA with training data, not entire dataset\n",
    "    p.fit(X_train)\n",
    "    X_train_reduced = p.transform(X_train)\n",
    "    X_test_reduced = p.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(lr=0.001, max_iters=2500)\n",
    "    model.fit(X_train_reduced, y_train)\n",
    "    predictions = model.predict(X_test_reduced)\n",
    "    print('Classification accuracy for %s PCA: %s'\n",
    "          % (s, accuracy(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
