{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from algora.base import BaseEstimator\n",
    "\n",
    "\n",
    "class KNNBase(BaseEstimator):\n",
    "    def __init__(self, k=5, distance_func=euclidean):\n",
    "        \"\"\"Base class for Nearest neighbors classifier and regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, default 5\n",
    "            The number of neighbors to take into account. If 0, all the\n",
    "            training examples are used.\n",
    "        distance_func : function, default euclidean distance\n",
    "            A distance function taking two arguments. Any function from\n",
    "            scipy.spatial.distance will do.\n",
    "        \"\"\"\n",
    "\n",
    "        self.k = None if k == 0 else k  # l[:None] returns the whole list\n",
    "        self.distance_func = distance_func\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        predictions = [self._predict_x(x) for x in X]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_x(self, x):\n",
    "        \"\"\"Predict the label of a single instance x.\"\"\"\n",
    "\n",
    "        # compute distances between x and all examples in the training set.\n",
    "        distances = (self.distance_func(x, example) for example in self.X)\n",
    "\n",
    "        # Sort all examples by their distance to x and keep their target value.\n",
    "        neighbors = sorted(((dist, target)\n",
    "                            for (dist, target) in zip(distances, self.y)),\n",
    "                           key=lambda x: x[0])\n",
    "\n",
    "        # Get targets of the k-nn and aggregate them (most common one or\n",
    "        # average).\n",
    "        neighbors_targets = [target for (_, target) in neighbors[:self.k]]\n",
    "\n",
    "        return self.aggregate(neighbors_targets)\n",
    "\n",
    "\n",
    "class KNNClassifier(KNNBase):\n",
    "    \"\"\"Nearest neighbors classifier.\n",
    "\n",
    "    Note: if there is a tie for the most common label among the neighbors, then\n",
    "    the predicted label is arbitrary.\"\"\"\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        \"\"\"Return the most common target label.\"\"\"\n",
    "\n",
    "        most_common_label = Counter(neighbors_targets).most_common(1)[0][0]\n",
    "        return most_common_label\n",
    "\n",
    "\n",
    "class KNNRegressor(KNNBase):\n",
    "    \"\"\"Nearest neighbors regressor.\"\"\"\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        \"\"\"Return the mean of all targets.\"\"\"\n",
    "\n",
    "        return np.mean(neighbors_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression mse 699.8333076147131\n",
      "classification accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from algora import knn\n",
    "from algora.metrics.metrics import mean_squared_error, accuracy\n",
    "\n",
    "\n",
    "def regression():\n",
    "    # Generate a random regression problem\n",
    "    X, y = make_regression(n_samples=500, n_features=5,\n",
    "                           n_informative=5, n_targets=1,\n",
    "                           noise=0.05, random_state=1111, bias=0.5)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                        random_state=1111)\n",
    "\n",
    "    model = knn.KNNRegressor(k=5, distance_func=distance.euclidean)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('regression mse', mean_squared_error(y_test, predictions))\n",
    "\n",
    "\n",
    "def classification():\n",
    "    X, y = make_classification(n_samples=500, n_features=5, n_informative=5,\n",
    "                               n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                               random_state=1111, class_sep=1.5, )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                        random_state=1111)\n",
    "\n",
    "    clf = knn.KNNClassifier(k=5, distance_func=distance.euclidean)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print('classification accuracy', accuracy(y_test, predictions))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regression()\n",
    "    classification()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
